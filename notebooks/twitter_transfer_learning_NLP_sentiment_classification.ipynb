{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for NLP: Sentiment Analysis on Twitter\n",
    "This notebook has used the \"Transfer Learning in NLP\" Feedlys' [notebook](https://github.com/feedly/ml-demos/blob/master/source/TransferLearningNLP.ipynb) described in this [article](https://blog.feedly.com/transfer-learning-in-nlp) as starting point.\n",
    "\n",
    "In this notebook, we show how transfer learning can be applied to detecting the sentiment of twitter posts related to Tesla, between bulls and bears.\n",
    "\n",
    "This notebook uses the work from [Howard and Ruder, Ulmfit](https://arxiv.org/pdf/1801.06146.pdf).\n",
    "The idea of the paper (and it implementation explained in the [fast.ai deep learning course](http://course.fast.ai/lessons/lesson10.html)) is to learn a language model trained on a very large dataset, e.g. a Wikipedia dump. The intuition is that if a model is able to predict the next word at each word, it means it has learnt something about the structure of the language we are using.\n",
    "\n",
    "[Word2vec](https://arxiv.org/pdf/1310.4546.pdf) and the likes have lead to huge improvements on various NLP tasks. This could be seen as a first step to transfer learning, where the pre-trained word vectors correspond to a transfer of the embedding layer.\n",
    "The ambition of [Ulmfit](https://arxiv.org/pdf/1801.06146.pdf) (and others like [ELMO](https://arxiv.org/pdf/1802.05365.pdf) or the [Transformer language model](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) recently introduced) is to progressively move the NLP field to the state where Computer Vision has risen thanks to the ImageNet challenge. Thanks to the ImageNet chalenge, today it is easy to download a model pre-trained on massive dataset of images, remove the last layer and replace it by a classifier or a regressor depending on the interest. \n",
    "\n",
    "With Ulmfit, the goal is for everyone to be able to use a pre-trained language model and use it a backbone which we can use along with a classifier and a regressor. The game-changing apect of transfer learning is that we are no longer limited by the size of trzining data! With only a fraction of the data size that was necessary before, we can trtain a classifier/regressor and have very good result with few labelled data.\n",
    "\n",
    "Given that labelled text data are difficult to get, in comparison with unlabelled text data which is almost infinite, transfer learning is likely to change radically the field of NLP, and help lead to a maturity state closer to computyer vision.\n",
    "\n",
    "The architecture for the language model used in ULMFit is the [AWD-LSTM language model](https://arxiv.org/pdf/1708.02182.pdf) by Merity.\n",
    "\n",
    "While we are using this language model for this experiment, we keep an eye open to a recently proposed character language model with [Contextual String Embedings](http://alanakbik.github.io/papers/coling2018.pdf) by Akbik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of around 150K Twitter posts that are either bullish or bearish. Training a model, with the whole training labelled dataset (150K Twitter posts) and our classifier results in a f1 score of 0.90.\n",
    "\n",
    "Note that if you are interested in Regression instead of classification, you can also do it following this [advice](http://forums.fast.ai/t/regression-using-ulmfit/18063/6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is organized as such:\n",
    "\n",
    "- Tokenize the reviews and create dictionaries\n",
    "- Download a pre-trained model and link the dictionary to the embedding layer of the model\n",
    "- Fine-tune the language model on the amaxon reviews texts\n",
    "\n",
    "We have then the backbone of our algorithm: a pre-trained language model fine-tuned on Twitter posts\n",
    "\n",
    "- Add a classifier to the language model and train the classifier layer only\n",
    "- Gradually defreeze successive layers to train different layers on the Twitter posts\n",
    "- Run a full classification task for several epochs\n",
    "- Use the model for inference!\n",
    "\n",
    "We end this notebook by looking at the specific effect of training size on the overall performance. This is to test the hypothesis that the ULMFit model does not need much labeled data to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we recommend working on a dedicated environment (e.g. mkvirtualenv fastai). Then clone the fastai github repo https://github.com/fastai/fastai and install requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = '/home/ubuntu/data'\n",
    "# root_path = '/home/paperspace/data'\n",
    "# root_path = '/Users/Miguel/git/data'\n",
    "# path = './data/stocktwits_posts'\n",
    "path = './data/twitter'\n",
    "data_file_nonextension_name = 'twitter_posts_preprocessed_20180420_20180913'\n",
    "data_file = f'{path}/{data_file_nonextension_name}.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fastai==0.7\n",
    "# ! pip install --force-reinstall Pillow==5.0.0\n",
    "# ! pip install opencv-python\n",
    "# ! apt update && apt install -y libsm6 libxext6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ln -s \"$root_path\" ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir \"$path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.lm_rnn import *\n",
    "import html\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, \\\n",
    "confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_twitter_posts = pd.read_json(\n",
    "    data_file, \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT : Yes should fix our oil addiction single h...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Next FUD from the TSLAQ camp. “TSLA could be d...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>-0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Performance 3 review: ‘The Eu marques per...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT : This guy is like that creepy stalker chic...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT : Yea, that \"not enough demand\" story is fr...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.3502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_body sentiment  \\\n",
       "0  RT : Yes should fix our oil addiction single h...   Bullish   \n",
       "1  Next FUD from the TSLAQ camp. “TSLA could be d...   Bullish   \n",
       "2  RT : Performance 3 review: ‘The Eu marques per...   Bullish   \n",
       "3  RT : This guy is like that creepy stalker chic...   Bullish   \n",
       "4  RT : Yea, that \"not enough demand\" story is fr...   Bullish   \n",
       "\n",
       "   vader_sentiment  \n",
       "0           0.4019  \n",
       "1          -0.7925  \n",
       "2           0.0000  \n",
       "3           0.2023  \n",
       "4           0.3502  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_twitter_posts[['clean_body', 'sentiment', 'vader_sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cases = {\n",
    "    'Bullish': 1,\n",
    "    'Bearish': 0,\n",
    "}\n",
    "\n",
    "def calculate_numeric_label(text_label):\n",
    "    return label_cases[text_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_twitter_posts['labels'] = df_clean_twitter_posts['sentiment'].apply(lambda text_label: calculate_numeric_label(text_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_twitter_posts = df_clean_twitter_posts.rename({'clean_body': 'text'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT : Yes should fix our oil addiction single h...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Next FUD from the TSLAQ camp. “TSLA could be d...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Performance 3 review: ‘The Eu marques per...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT : This guy is like that creepy stalker chic...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT : Yea, that \"not enough demand\" story is fr...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  labels  \\\n",
       "0  RT : Yes should fix our oil addiction single h...   Bullish       1   \n",
       "1  Next FUD from the TSLAQ camp. “TSLA could be d...   Bullish       1   \n",
       "2  RT : Performance 3 review: ‘The Eu marques per...   Bullish       1   \n",
       "3  RT : This guy is like that creepy stalker chic...   Bullish       1   \n",
       "4  RT : Yea, that \"not enough demand\" story is fr...   Bullish       1   \n",
       "\n",
       "   vader_sentiment  \n",
       "0           0.4019  \n",
       "1          -0.7925  \n",
       "2           0.0000  \n",
       "3           0.2023  \n",
       "4           0.3502  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_twitter_posts[['text', 'sentiment', 'labels', 'vader_sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
      "                 8,      9,\n",
      "            ...\n",
      "            158995, 158996, 158997, 158998, 158999, 159000, 159001, 159002,\n",
      "            159003, 159004],\n",
      "           dtype='int64', length=159005)\n"
     ]
    }
   ],
   "source": [
    "print(df_clean_twitter_posts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_posts = df_clean_twitter_posts.query('labels!=2').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=159005, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df_twitter_posts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN/TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.75, validate_percent=0, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, _, test = train_validate_test_split(df_twitter_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data contains 119253 examples\n",
      "The test data contains 39752 examples\n"
     ]
    }
   ],
   "source": [
    "print(f'The train data contains {len(train)} examples')\n",
    "print(f'The test data contains {len(test)} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path(path)\n",
    "\n",
    "CLAS_PATH=PATH/'stocktwits_posts_class'\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=PATH/'stocktwits_posts_lm'\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = train[['labels','text']]\n",
    "df_val = test[['labels','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120640</th>\n",
       "      <td>1</td>\n",
       "      <td>#donotpanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>0</td>\n",
       "      <td>Must. Get. The. Gas. Line. Through.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107244</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : Thanks Jack. To be clear, I am not a cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : Tesla 1st, 2nd &amp;&amp; 3rd in August sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101667</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : Elon Musk in Shanghai signs prelim agreem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105551</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : Maybe worth trying: insert a 1m diameter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20209</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : They seem to have delayed the 6000/wk ram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70939</th>\n",
       "      <td>0</td>\n",
       "      <td>Clarification. The following statement was poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148460</th>\n",
       "      <td>1</td>\n",
       "      <td>Model 3 is Popular Mechanics’ Car of the Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78790</th>\n",
       "      <td>1</td>\n",
       "      <td>Live: Watch #SpaceX launch from Cape Canaveral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels                                               text\n",
       "120640       1                                        #donotpanic\n",
       "35871        0                Must. Get. The. Gas. Line. Through.\n",
       "107244       1  RT : Thanks Jack. To be clear, I am not a cons...\n",
       "18294        1         RT : Tesla 1st, 2nd && 3rd in August sales\n",
       "101667       1  RT : Elon Musk in Shanghai signs prelim agreem...\n",
       "105551       1  RT : Maybe worth trying: insert a 1m diameter ...\n",
       "20209        1  RT : They seem to have delayed the 6000/wk ram...\n",
       "70939        0  Clarification. The following statement was poo...\n",
       "148460       1      Model 3 is Popular Mechanics’ Car of the Year\n",
       "78790        1     Live: Watch #SpaceX launch from Cape Canaveral"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trn.to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "# df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "df_trn.to_json(\n",
    "    f'{CLAS_PATH}/{data_file_nonextension_name}_train.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")\n",
    "\n",
    "df_val.to_json(\n",
    "    f'{CLAS_PATH}/{data_file_nonextension_name}_test.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['Bearish', 'Bullish']\n",
    "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Miguel/anaconda3/envs/conda36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/Miguel/anaconda3/envs/conda36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_trn['labels'] = 0\n",
    "df_val['labels'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to fine tune the language model so it's ok to take some of the test set in our train data\n",
    "# for the lm fine-tuning\n",
    "# df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "# df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "df_trn.to_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_train.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")\n",
    "\n",
    "df_val.to_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_test.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:labels\n",
      "1:text\n"
     ]
    }
   ],
   "source": [
    "df_trn = pd.read_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_train.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")# [['text', 'labels']]\n",
    "\n",
    "df_val = pd.read_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_test.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip'\n",
    ")\n",
    "\n",
    "for i, r in enumerate(df_val):\n",
    "    print(f'{i}:{r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use functions from the fast.ai course to get data\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    # print(df[n_lbls])\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): \n",
    "        texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        df = r.rename(columns={x:y for x,y in zip(r.columns,range(0,len(r.columns)))})\n",
    "        # print(r)\n",
    "        tok_, labels_ = get_texts(df, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels\n",
    "\n",
    "# df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "# df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)\n",
    "\n",
    "df_trn = pd.read_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_train.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip', chunksize=chunksize\n",
    ")# [['text', 'labels']]\n",
    "\n",
    "df_val = pd.read_json(\n",
    "    f'{LM_PATH}/{data_file_nonextension_name}_test.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip', chunksize=chunksize\n",
    ")# [['text', 'labels']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.json.json.JsonReader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# This cell can take quite some time if your dataset is large\n",
    "# Run it once and comment it for later use\n",
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once and comment everything but the load statements for later use\n",
    "(LM_PATH/'tmp').mkdir(exist_ok=True)\n",
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t_up', 111265),\n",
       " ('$', 99242),\n",
       " ('tsla', 70987),\n",
       " ('1', 69683),\n",
       " ('\\n', 68714),\n",
       " ('xbos', 68714),\n",
       " ('xfld', 68714),\n",
       " ('.', 50203),\n",
       " ('the', 27992),\n",
       " ('to', 23149),\n",
       " (',', 20141),\n",
       " ('is', 17428),\n",
       " ('a', 16626),\n",
       " ('!', 16082),\n",
       " ('and', 12584),\n",
       " ('this', 11816),\n",
       " ('i', 10665),\n",
       " ('of', 10561),\n",
       " ('in', 10285),\n",
       " ('it', 9900),\n",
       " ('?', 9392),\n",
       " ('for', 9199),\n",
       " ('&', 8803),\n",
       " ('you', 8273),\n",
       " ('on', 8019)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the most common tokens\n",
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hotline', 1),\n",
       " ('3.38', 1),\n",
       " ('entails', 1),\n",
       " ('haha-', 1),\n",
       " ('.longs', 1),\n",
       " ('yang', 1),\n",
       " ('23.5', 1),\n",
       " ('.musk', 1),\n",
       " ('bullsh', 1),\n",
       " ('chipmakers', 1),\n",
       " ('sheered', 1),\n",
       " ('pseudo', 1),\n",
       " ('clammering', 1),\n",
       " ('robot', 1),\n",
       " ('stifle', 1),\n",
       " ('drop-', 1),\n",
       " ('short=', 1),\n",
       " ('duuumb', 1),\n",
       " ('4.22', 1),\n",
       " ('ajit', 1),\n",
       " ('jain', 1),\n",
       " ('301.84', 1),\n",
       " ('afterall', 1),\n",
       " ('yoyo', 1),\n",
       " ('onion', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the least common tokens\n",
    "freq.most_common()[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your vocabulary by keeping only the most common tokens that appears frequently enough\n",
    "# and constrain the size of your vocabulary. We follow here the 60k recommendation.\n",
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)\n",
    "\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "\n",
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13221, 68714)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre trained Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/\n",
      "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
      "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:21:29 (81.8 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html’ saved [857/857]\n",
      "\n",
      "Loading robots.txt; please ignore errors.\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/robots.txt\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2018-08-28 15:21:29 ERROR 404: Not Found.\n",
      "\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/?C=N;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=N;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:21:29 (78.7 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=N;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/?C=M;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=M;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:21:29 (96.0 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=M;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/?C=S;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=S;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:21:29 (115 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=S;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/?C=D;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=D;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:21:29 (121 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=D;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:21:29--  http://files.fast.ai/models/wt103/bwd_wt103.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387687 (441M) [text/plain]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/bwd_wt103.h5’\n",
      "\n",
      "models/wt103/bwd_wt 100%[===================>] 440.97M  21.4MB/s    in 37s     \n",
      "\n",
      "2018-08-28 15:22:07 (11.9 MB/s) - ‘./data/stocktwits_posts/models/wt103/bwd_wt103.h5’ saved [462387687/462387687]\n",
      "\n",
      "--2018-08-28 15:22:07--  http://files.fast.ai/models/wt103/bwd_wt103_enc.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387634 (441M) [text/plain]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/bwd_wt103_enc.h5’\n",
      "\n",
      "models/wt103/bwd_wt 100%[===================>] 440.97M  34.1MB/s    in 16s     \n",
      "\n",
      "2018-08-28 15:22:23 (27.8 MB/s) - ‘./data/stocktwits_posts/models/wt103/bwd_wt103_enc.h5’ saved [462387634/462387634]\n",
      "\n",
      "--2018-08-28 15:22:23--  http://files.fast.ai/models/wt103/fwd_wt103.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387687 (441M) [text/plain]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/fwd_wt103.h5’\n",
      "\n",
      "models/wt103/fwd_wt 100%[===================>] 440.97M  29.6MB/s    in 14s     \n",
      "\n",
      "2018-08-28 15:22:36 (32.5 MB/s) - ‘./data/stocktwits_posts/models/wt103/fwd_wt103.h5’ saved [462387687/462387687]\n",
      "\n",
      "--2018-08-28 15:22:36--  http://files.fast.ai/models/wt103/fwd_wt103_enc.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387634 (441M) [text/plain]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/fwd_wt103_enc.h5’\n",
      "\n",
      "models/wt103/fwd_wt 100%[===================>] 440.97M  34.0MB/s    in 13s     \n",
      "\n",
      "2018-08-28 15:22:49 (34.0 MB/s) - ‘./data/stocktwits_posts/models/wt103/fwd_wt103_enc.h5’ saved [462387634/462387634]\n",
      "\n",
      "--2018-08-28 15:22:49--  http://files.fast.ai/models/wt103/itos_wt103.pkl\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4161252 (4.0M) [text/plain]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/itos_wt103.pkl’\n",
      "\n",
      "models/wt103/itos_w 100%[===================>]   3.97M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2018-08-28 15:22:49 (41.2 MB/s) - ‘./data/stocktwits_posts/models/wt103/itos_wt103.pkl’ saved [4161252/4161252]\n",
      "\n",
      "--2018-08-28 15:22:49--  http://files.fast.ai/models/wt103/?C=N;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=N;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:22:50 (135 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=N;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:22:50--  http://files.fast.ai/models/wt103/?C=M;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=M;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:22:50 (124 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=M;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:22:50--  http://files.fast.ai/models/wt103/?C=S;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=S;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:22:50 (124 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=S;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-28 15:22:50--  http://files.fast.ai/models/wt103/?C=D;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘./data/stocktwits_posts/models/wt103/index.html?C=D;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-28 15:22:50 (122 MB/s) - ‘./data/stocktwits_posts/models/wt103/index.html?C=D;O=D’ saved [857/857]\n",
      "\n",
      "FINISHED --2018-08-28 15:22:50--\n",
      "Total wall clock time: 1m 21s\n",
      "Downloaded: 14 files, 1.7G in 1m 20s (22.2 MB/s)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this cell to download the pre-trained model.\n",
    "# It will be placed into the PATH that you defined earlier.\n",
    "! wget -nH -r -np -P {path} http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights of the model\n",
    "em_sz,nh,nl = 400,1150,3\n",
    "\n",
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'\n",
    "\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238462, 400)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the word embedding layer and keep a 'mean word' for unknown tokens\n",
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)\n",
    "\n",
    "enc_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vocabulary on which the pre-trained model was trained\n",
    "# Define an embedding matrix with the vocabulary of our dataset\n",
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})\n",
    "\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new embedding matrix for the pre-trained model\n",
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learner object to do the fine-tuning\n",
    "# Here we will freeze everything except the embedding layer, so that we can have a better \n",
    "# embedding for unknown words than just the mean embedding on which we initialise it.\n",
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n",
    "\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "\n",
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)\n",
    "\n",
    "learner.model.load_state_dict(wgts)\n",
    "\n",
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf246ba4ca147b7932f5f035eb239f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      5.041968   4.713975   0.308568  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 4.71397]), 0.30856804667612758]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run one epoch of fine-tuning \n",
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model and unfreeze everything to later fine-tune the whole model\n",
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c5438fc620448b95ebf0e751cbfe09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.525703   3.337948   0.427656  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft_after_lr_find')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft_after_lr_find')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee5277450a44d608ea4d0ba5921fe1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.772837   3.538827   0.416185  \n",
      "    1      3.352943   3.17047    0.453603                   \n",
      "    2      3.012864   2.885514   0.491399                   \n",
      "    3      2.771227   2.681538   0.523959                   \n",
      "    4      2.559092   2.521284   0.551148                   \n",
      "    5      2.397784   2.397235   0.573595                   \n",
      "    6      2.271078   2.298868   0.592203                   \n",
      "    7      2.174226   2.215298   0.608304                   \n",
      "    8      2.080278   2.148482   0.621696                   \n",
      "    9      1.99816    2.093355   0.63235                    \n",
      "    10     1.935472   2.048272   0.641846                   \n",
      "    11     1.873651   2.014468   0.649343                   \n",
      "    12     1.818698   1.987754   0.654887                   \n",
      "    13     1.794235   1.967544   0.659171                   \n",
      "    14     1.773556   1.957359   0.661337                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.95736]), 0.66133687986821232]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this if you want to highly tune the LM to the Stocktwits data, with 15 epochs\n",
    "# use_clr controls the shape of the cyclical (triangular) learning rate\n",
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Backbone for further classification!!\n",
    "learner.save('lm1')\n",
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('lm1_enc')\n",
    "learner.load('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'plot_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-81b1207950d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'plot_loss'"
     ]
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going back to classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we spent some time fine-tuning the language model on our Stocktwits data, let's see if we can classify easily these reviews.\n",
    "As before, some cells should be run once, and then use data loaders for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "# df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)\n",
    "df_trn = pd.read_json(\n",
    "    f'{CLAS_PATH}/{data_file_nonextension_name}_train.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip', chunksize=chunksize\n",
    ")# [['text', 'labels']]\n",
    "\n",
    "df_val = pd.read_json(\n",
    "    f'{CLAS_PATH}/{data_file_nonextension_name}_test.json.gz', \n",
    "    orient='records', \n",
    "    lines=True, compression='gzip', chunksize=chunksize\n",
    ")# [['text', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13221"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')\n",
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "In this part, we adopt an unusual train/test hierarchy. While it's common to train on a big dataset and thewn test on a small one, here we wanrt to test the hypothesis that the model can learn with few training data. Hence we take less data for training than for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train data contains 68714 examples\n",
    "# The test data contains 22905 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select here the 'size' first reviews of our dataset\n",
    "# The paper claims that it's possible to achieve very good results with few labeled examples\n",
    "# So let's try with 100 examples for training, and 5000 examples for validation.\n",
    "# We encourage you to try different values to see the effect of data size on performance.\n",
    "# trn_size = 100\n",
    "# val_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_size = 1000\n",
    "val_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')\n",
    "\n",
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))\n",
    "\n",
    "train = random.sample(list(zip(trn_clas, trn_labels)), trn_size)\n",
    "trn_clas = np.array([item[0] for item in train])\n",
    "trn_labels = np.array([item[1] for item in train])\n",
    "del train\n",
    "\n",
    "validation = random.sample(list(zip(val_clas, val_labels)), val_size)\n",
    "val_clas = np.array([item[0] for item in validation])\n",
    "val_labels = np.array([item[1] for item in validation])\n",
    "del validation\n",
    "\n",
    "\n",
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48\n",
    "\n",
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ccheck that the validation dataset is well balanced so acccuracy is a good metric\n",
    "# We'll also check other metrics usual for binary classification (precision, recall, f1 score)\n",
    "len(trn_labels[trn_labels == 1]) / len(trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the model, here it a classifier on top of an RNN language model\n",
    "# We load the language model encoder that we fine tuned before\n",
    "# We freeze everything but the last layer, so that we can train the classification layer only.\n",
    "#load the saved weights from before, and freeze everything until the last layer\n",
    "# from fastai.lm_rnn import *\n",
    "\n",
    "md = ModelData(PATH, trn_dl, val_dl)\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])\n",
    "\n",
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]\n",
    "\n",
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3697f7aa874d799593dcc2f8bdc6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [00:00<00:00, 37.79it/s, loss=4.26] \n",
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "# trn_size = 1000\n",
    "# val_size = 5000\n",
    "learn.lr_find(lrs/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69865049ce5745c8baab3786e1281916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                \n",
      "    0      0.715853   126.110563 0.630904  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trn_size = 100\n",
    "# val_size = 5000\n",
    "learn.lr_find(lrs/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3aeed8a6f2f42ecbcff494394b95de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.694678   0.629315   0.642416  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.62932]), 0.64241580438416968]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run one epoch on the classification layer\n",
    "# trn_size = 1000\n",
    "# val_size = 5000\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6c093047814b5fb3eb27d2e554d8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                \n",
      "    0      0.761598   0.66294    0.630888  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.66294]), 0.63088820578044869]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run one epoch on the classification layer\n",
    "# trn_size = 100\n",
    "# val_size = 5000\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "learn.save('clas_0')\n",
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282f88a49db04e9980364fa267384c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.644149   0.650167   0.618549  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.65017]), 0.6185491113389312]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradually unfreeze another layer to train a bit more parameters than just the classifier layer\n",
    "# trn_size = 1000\n",
    "# val_size = 5000\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb66581023d48e195aa31e085361a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                \n",
      "    0      0.655339   0.663206   0.63076   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.66321]), 0.63075985164196158]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradually unfreeze another layer to train a bit more parameters than just the classifier layer\n",
    "# trn_size = 100\n",
    "# val_size = 5000\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "learn.save('clas_1')\n",
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5e629e5d77455c99f72a59d80da8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.63516    0.60979    0.683978  \n",
      "    1      0.625419   0.765658   0.583117                  \n",
      "    2      0.631421   0.593774   0.674622                  \n",
      "    3      0.616925   0.605305   0.670292                  \n",
      "    4      0.61349    0.586114   0.679961                  \n",
      "    5      0.585603   0.613809   0.670628                  \n",
      "    6      0.576287   0.570074   0.6972                    \n",
      "    7      0.558553   0.573434   0.693967                  \n",
      "    8      0.557649   0.591485   0.693959                  \n",
      "    9      0.54189    0.57117    0.696776                  \n",
      "    10     0.538101   0.575696   0.697913                  \n",
      "    11     0.54434    0.571325   0.700562                  \n",
      "    12     0.541779   0.566735   0.703331                  \n",
      "    13     0.544632   0.56665    0.702571                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.56665]), 0.70257074984389456]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfreeze everything and train for a few epochs on the whole set of parameters of the model\n",
    "# trn_size = 1000\n",
    "# val_size = 5000\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5953f90500c14945bfd7510b4eb2f2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                \n",
      "    0      0.565184   0.658257   0.630736  \n",
      "    1      0.609008   0.643067   0.641461                \n",
      "    2      0.589626   0.629926   0.644149                \n",
      "    3      0.582622   0.643003   0.634057                \n",
      "    4      0.577048   0.674303   0.619072                \n",
      "    5      0.561641   0.716868   0.607993                \n",
      "    6      0.554197   0.673983   0.632581                \n",
      "    7      0.529539   0.68012    0.64159                 \n",
      "    8      0.538618   0.701428   0.633327                \n",
      "    9      0.525071   0.738133   0.618959                \n",
      "    10     0.502935   0.736744   0.620724                \n",
      "    11     0.487381   0.719305   0.634891                \n",
      "    12     0.501681   0.742144   0.632685                \n",
      "    13     0.490324   0.749581   0.631273                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.74958]), 0.63127326669259676]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfreeze everything and train for a few epochs on the whole set of parameters of the model\n",
    "# trn_size = 100\n",
    "# val_size = 5000\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Nonw, let's play with the model we've just learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=int(trn_labels.max())+1\n",
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]\n",
    "\n",
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')\n",
    "learn.load('clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(input_str: str):\n",
    "\n",
    "    # predictions are done on arrays of input.\n",
    "    # We only have a single input, so turn it into a 1x1 array\n",
    "    texts = [input_str]\n",
    "\n",
    "    # tokenize using the fastai wrapper around spacy\n",
    "    tok = [t.split() for t in texts]\n",
    "    # tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "\n",
    "    # turn into integers for each word\n",
    "    encoded = [stoi[p] for p in tok[0]]\n",
    "\n",
    "    idx = np.array(encoded)[None]\n",
    "    idx = np.transpose(idx)\n",
    "    tensorIdx = VV(idx)\n",
    "    m.eval()\n",
    "    m.reset()\n",
    "    p = m.forward(tensorIdx)\n",
    "    return np.argmax(p[0][0].data.cpu().numpy())\n",
    "\n",
    "def prediction(texts):\n",
    "    \"\"\"Do the prediction on a list of texts\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        encoded = text\n",
    "        idx = np.array(encoded)[None]\n",
    "        idx = np.transpose(idx)\n",
    "        tensorIdx = VV(idx)\n",
    "        m.eval()\n",
    "        m.reset()\n",
    "        p = m.forward(tensorIdx)\n",
    "        y.append(np.argmax(p[0][0].data.cpu().numpy()))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.051624298095703125\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I like Feedly\"\n",
    "start = time()\n",
    "print(get_sentiment(sentence))\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "y = prediction(list(val_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --> 0.6818\n",
      "Precision --> 0.7908163265306123\n",
      "F1 score --> 0.7571363150664021\n",
      "Recall score --> 0.726207906295754\n",
      "[[ 929  656]\n",
      " [ 935 2480]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.59      0.54      1585\n",
      "          1       0.79      0.73      0.76      3415\n",
      "\n",
      "avg / total       0.70      0.68      0.69      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show relevant metrics for binary classification\n",
    "# We encourage you to try training the classifier with different data size and its effect on performance\n",
    "# trn_size = 1000\n",
    "# val_size = 5000\n",
    "print(f'Accuracy --> {accuracy_score(y, val_labels)}')\n",
    "print(f'Precision --> {precision_score(y, val_labels)}')\n",
    "print(f'F1 score --> {f1_score(y, val_labels)}')\n",
    "print(f'Recall score --> {recall_score(y, val_labels)}')\n",
    "print(confusion_matrix(y, val_labels))\n",
    "print(classification_report(y, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --> 0.5966\n",
      "Precision --> 0.6407337128399747\n",
      "F1 score --> 0.6676552974130829\n",
      "Recall score --> 0.696938424492604\n",
      "[[ 957 1136]\n",
      " [ 881 2026]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.46      0.49      2093\n",
      "          1       0.64      0.70      0.67      2907\n",
      "\n",
      "avg / total       0.59      0.60      0.59      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show relevant metrics for binary classification\n",
    "# We encourage you to try training the classifier with different data size and its effect on performance\n",
    "# trn_size = 100\n",
    "# val_size = 5000\n",
    "print(f'Accuracy --> {accuracy_score(y, val_labels)}')\n",
    "print(f'Precision --> {precision_score(y, val_labels)}')\n",
    "print(f'F1 score --> {f1_score(y, val_labels)}')\n",
    "print(f'Recall score --> {recall_score(y, val_labels)}')\n",
    "print(confusion_matrix(y, val_labels))\n",
    "print(classification_report(y, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What training size do we need?\n",
    "The language model has already learnt a lot about the syntax. It is very knowledgeable about the context in which words appear in sentences. However, the language model does not contain any notion of [meaning](https://en.wikipedia.org/wiki/Meaning_%28linguistics%29). This problem is well summarised in [Emily Bender's tweet](https://twitter.com/emilymbender/status/1024042044035985408) during a very interesting twiter thread that occur in July around meaning in NLP. A cool summary of this thread can be found in the [Hugging Face](https://medium.com/huggingface/learning-meaning-in-natural-language-processing-the-semantics-mega-thread-9c0332dfe28e) blogpost. Hence the meaning in language is very likely to be learned through supervision, with the help of ground-truth examples.\n",
    "\n",
    "However, when we perform some NLP tasks, sentiment analysis in our example, both syntax and meaning are important!\n",
    "The idea is that you can save a lot of time by being taught with a lot of blind synatx first, and then learning meaning. Think of when you start learning a complete new field. Well, it is far easier to learn it in your mother tongue than in another language you master less. \n",
    "\n",
    "The big practical gain here is that once you \"know\" a language, you need less supervised examples to learn a new thing! In our example, it means we need less labeled reviews for us to learn a relevant classifier.\n",
    "\n",
    "Let's verify this hypothesis by training a classifier with several training size and see how this size affects the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train data contains 68714 examples\n",
    "# The test data contains 22905 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')\n",
    "\n",
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(trn_size, val_size):\n",
    "\n",
    "    train = random.sample(list(zip(trn_clas, trn_labels)), trn_size)\n",
    "    aux_trn_clas = np.array([item[0] for item in train])\n",
    "    aux_trn_labels = np.array([item[1] for item in train])\n",
    "    del train\n",
    "\n",
    "    validation = random.sample(list(zip(val_clas, val_labels)), val_size)\n",
    "    aux_val_clas = np.array([item[0] for item in validation])\n",
    "    aux_val_labels = np.array([item[1] for item in validation])\n",
    "    del validation\n",
    "\n",
    "\n",
    "    bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "    vs = len(itos)\n",
    "    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "    bs = 48\n",
    "\n",
    "    min_lbl = aux_trn_labels.min()\n",
    "    aux_trn_labels -= min_lbl\n",
    "    aux_val_labels -= min_lbl\n",
    "    c=int(aux_trn_labels.max())+1\n",
    "\n",
    "    # Load data in relevant structures\n",
    "    trn_ds = TextDataset(aux_trn_clas, aux_trn_labels)\n",
    "    val_ds = TextDataset(aux_val_clas, aux_val_labels)\n",
    "    trn_samp = SortishSampler(aux_trn_clas, key=lambda x: len(aux_trn_clas[x]), bs=bs//2)\n",
    "    val_samp = SortSampler(aux_val_clas, key=lambda x: len(aux_val_clas[x]))\n",
    "    trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "\n",
    "    # Define the model and load the backbone lamguage model\n",
    "    md = ModelData(PATH, trn_dl, val_dl)\n",
    "    dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])\n",
    "\n",
    "    m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "              layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "              dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "\n",
    "    opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n",
    "    learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "    learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "    learn.clip=25.\n",
    "    learn.metrics = [accuracy]\n",
    "\n",
    "    lr=3e-3\n",
    "    lrm = 2.6\n",
    "    lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "\n",
    "    lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "    wd = 1e-7\n",
    "    wd = 0\n",
    "    learn.load_encoder('lm1_enc')\n",
    "\n",
    "    learn.freeze_to(-1)\n",
    "\n",
    "    # Find th learning rate\n",
    "    learn.lr_find(lrs/1000)\n",
    "\n",
    "    # Run one epoch on the classification layer\n",
    "    learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))\n",
    "\n",
    "    # Save the trained model\n",
    "    learn.save(f'{trn_size}clas_0')\n",
    "    learn.load(f'{trn_size}clas_0')\n",
    "\n",
    "    # Gradually unfreeze another layer to train a bit more parameters than just the classifier layer\n",
    "    learn.freeze_to(-2)\n",
    "    learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))\n",
    "\n",
    "    # Save the trained model\n",
    "    learn.save(f'{trn_size}clas_1')\n",
    "    learn.load(f'{trn_size}clas_1')\n",
    "\n",
    "    # Unfreeze everything and train for a few epochs on the whole set of parameters of the model\n",
    "    learn.unfreeze()\n",
    "    learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))\n",
    "\n",
    "    # Save the model\n",
    "    learn.sched.plot_loss()\n",
    "    learn.save(f'{trn_size}clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Experiment with training size 5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a8e09c1dd4e619cf926e4f279d02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 169/209 [01:59<00:28,  1.41it/s, loss=3.03] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8802325259246e28fefaa35751522b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.634094   0.597489   0.674409  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd2c3aab52c4c7dae26e27d39610292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.634767   0.600288   0.686575  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8cbfa041634b74bc4c5381744c8ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.636559   0.584767   0.693665  \n",
      "    1      0.636961   0.565862   0.712828                    \n",
      "    2      0.597901   0.546654   0.722627                    \n",
      "    3      0.582868   0.536576   0.724297                    \n",
      "    4      0.568843   0.530237   0.736169                    \n",
      "    5      0.556414   0.518603   0.736022                    \n",
      " 54%|█████▎    | 112/209 [07:53<06:50,  4.23s/it, loss=0.546]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5c72f0a77015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Experiment with training size {trn_size}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time cost: {t}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-2984824e49ff>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(trn_size, val_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Unfreeze everything and train for a few epochs on the whole set of parameters of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The train data contains 68714 examples\n",
    "# The test data contains 22905 examples\n",
    "from time import time\n",
    "val_size = 22905\n",
    "for trn_size in [5000, 10000, 20000, 50000, 68714]:\n",
    "    print('#'*50)\n",
    "    print(f'Experiment with training size {trn_size}')\n",
    "    start = time()\n",
    "    experiment(trn_size, val_size)\n",
    "    t = time() - start\n",
    "    print(f'Time cost: {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'68714clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n"
     ]
    }
   ],
   "source": [
    "y = prediction(list(val_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_size = 68714\n",
    "# val_size = 5000\n",
    "print(f'Accuracy --> {accuracy_score(y, val_labels)}')\n",
    "print(f'Precision --> {precision_score(y, val_labels)}')\n",
    "print(f'F1 score --> {f1_score(y, val_labels)}')\n",
    "print(f'Recall score --> {recall_score(y, val_labels)}')\n",
    "print(confusion_matrix(y, val_labels))\n",
    "print(classification_report(y, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notebook issues here, you might want to run this cell from a python script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "y = prediction(list(val_clas)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision --> 0.9661016949152542\n",
      "F1 score --> 0.95\n",
      "Recall score --> 0.9344262295081968\n",
      "[[37  2]\n",
      " [ 4 57]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92        39\n",
      "          1       0.97      0.93      0.95        61\n",
      "\n",
      "avg / total       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision --> {precision_score(y, val_labels[:100])}')\n",
    "print(f'F1 score --> {f1_score(y, val_labels[:100])}')\n",
    "print(f'Recall score --> {recall_score(y, val_labels[:100])}')\n",
    "print(confusion_matrix(y, val_labels[:100]))\n",
    "print(classification_report(y, val_labels[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
