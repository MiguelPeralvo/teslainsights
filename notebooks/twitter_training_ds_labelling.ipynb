{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bulls/bears datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import preprocessor as p\n",
    "import mysql.connector as sql\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from sqlalchemy import create_engine\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.options.display.max_colwidth = 400\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION)\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_username = os.getenv('AUTOMLPREDICTOR_DB_SSH_USER')\n",
    "ssh_password = os.getenv('AUTOMLPREDICTOR_DB_SSH_PASSWORD')\n",
    "\n",
    "db_host = os.getenv('AUTOMLPREDICTOR_DB_SERVER_IP', '127.0.0.1')\n",
    "db_user = 'root'\n",
    "db_password = os.getenv('AUTOMLPREDICTOR_DB_SQL_PASSWORD')\n",
    "db_port = 3306\n",
    "db = 'automlpredictor_db_dashboard'\n",
    "use_ssh = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./data/twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friends_followers(leaders_path, friends_path, followers_path):\n",
    "    df_leaders = pd.read_json(leaders_path, lines=True, orient=str)\n",
    "    df_leaders['id'] = df_leaders[['id']].astype(np.int64)\n",
    "    \n",
    "    df_friends = pd.read_json(friends_path, lines=True, orient=str) # .reset_index(drop=True).set_index(['id'])\n",
    "    df_followers = pd.read_json(followers_path, lines=True, orient=str).reset_index(drop=True).set_index(['id'])\n",
    "    \n",
    "    \n",
    "    df_intersection = pd.merge(\n",
    "        df_friends[['id']], df_followers, left_on=['id'], \n",
    "        right_index=True, how='inner', sort=False, suffixes=['', '_']\n",
    "    )\n",
    "    \n",
    "    df_union = pd.concat([df_intersection, df_leaders]).drop_duplicates().reset_index(drop=True).set_index(['id'])\n",
    "    return df_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bears = get_friends_followers(f'{data_path}/bears_20180912.json',\n",
    "                                 f'{data_path}/bears_friends_20180916.json', \n",
    "                                 f'{data_path}/bears_followers_20180914.json')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulls = get_friends_followers(f'{data_path}/bulls_20180912.json',\n",
    "                                 f'{data_path}/bulls_friends_20180915.json', \n",
    "                                 f'{data_path}/bulls_followers_20180916.json')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulls.to_json(\n",
    "    f'{data_path}/extended_bulls_20180912.json', orient='records', lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bears.to_json(\n",
    "    f'{data_path}/extended_bears_20180912.json', orient='records', lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulls_bears = pd.concat(\n",
    "    [df_bulls, df_bears], keys=['Bullish', 'Bearish',]\n",
    ").reset_index().drop(['level_1'], axis=1).rename(\n",
    "    {'level_0': 'sentiment'}, axis=1\n",
    ").set_index(['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bulls_bears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the posts to enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(use_ssh, q, db_host, db_user, db_password, db_port, db, ssh_username, ssh_password, charset='utf8mb4'):\n",
    "\n",
    "    if use_ssh:\n",
    "        with SSHTunnelForwarder(\n",
    "                ssh_address_or_host=(db_host, 22),\n",
    "                ssh_password=ssh_password,\n",
    "                ssh_username=ssh_username,\n",
    "                remote_bind_address=('127.0.0.1', db_port)\n",
    "        ) as server:\n",
    "            conn = sql.connect(host='127.0.0.1',\n",
    "                               port=server.local_bind_port,\n",
    "                               user=db_user,\n",
    "                               passwd=db_password,\n",
    "                               db=db,\n",
    "                               charset=charset)\n",
    "            response = pd.read_sql_query(q, conn)\n",
    "            conn.close()\n",
    "            return response\n",
    "    else:\n",
    "        conn = sql.connect(host=db_host,\n",
    "                           port=db_port,\n",
    "                           user=db_user,\n",
    "                           passwd=db_password,\n",
    "                           db=db,\n",
    "                           charset=charset)\n",
    "        response = pd.read_sql_query(q, conn)\n",
    "        conn.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-18 11:37:51,092 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_7.2p2)\n",
      "2018-09-18 11:37:51,269 - paramiko.transport - INFO - Authentication (publickey) failed.\n",
      "2018-09-18 11:37:51,307 - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_7.2p2)\n",
      "2018-09-18 11:37:51,479 - paramiko.transport - INFO - Authentication (publickey) successful!\n"
     ]
    }
   ],
   "source": [
    "sql_posts_to_enrich = \"\"\"\n",
    "SELECT post_id, post_type, body, impact, link, user_name, \n",
    "created_at_epoch_ms, client_received_epoch_ms, \n",
    "sentiment_ml_model as original_ml_sentiment, \n",
    "sentiment_vader_normalized, \n",
    "sentiment_mixed as original_sentiment_mixed\n",
    "FROM automlpredictor_db_dashboard.analysis_posts_sentiment\n",
    " WHERE created_at_epoch_ms >=(SELECT UNIX_TIMESTAMP(NOW())*1000-(14*24*3600000)) \n",
    " AND post_type in ('twitter-topic', 'twitter-user');\n",
    "\"\"\"\n",
    "\n",
    "df_posts_to_enrich = query(\n",
    "    use_ssh, sql_posts_to_enrich, db_host, db_user, db_password, db_port, db, \n",
    "    ssh_username, ssh_password\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts_to_enrich.to_json(\n",
    "    f'{data_path}/twitter_posts_pre_enrichment_20180918.json.gz', \n",
    "    orient='records', lines=True, compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_posts_to_enrich = pd.read_json(\n",
    "    f'{data_path}/twitter_posts_pre_enrichment_20180918.json.gz', \n",
    "    lines=True, orient=str, compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched = pd.merge(\n",
    "    df_posts_to_enrich, df_bulls_bears, left_on=['user_name'], \n",
    "    right_index=True, how='inner', sort=False\n",
    ")# .rename(\n",
    "#     {\n",
    "#         'text': 'body'\n",
    "#     }\n",
    "# )\n",
    "#         'favorite_count': 'likes.total',\n",
    "#         'retweet_count': 'retweet.total',\n",
    "#     }, axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched.to_json(\n",
    "    f'{data_path}/twitter_posts_post_enrichment_20180901_20180918.json.gz', \n",
    "    orient='records', lines=True, compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_unknown_user = pd.merge(\n",
    "    df_posts_to_enrich, df_bulls_bears, left_on=['user_name'], \n",
    "    right_index=True, how='left', sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_enriched_unknown_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
